{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction - Model Training and Evaluation\n",
    "\n",
    "This notebook demonstrates the complete model training and evaluation pipeline using the modular components.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#setup)\n",
    "2. [Data Preprocessing](#preprocessing)\n",
    "3. [Model Training](#training)\n",
    "4. [Model Evaluation](#evaluation)\n",
    "5. [Model Comparison](#comparison)\n",
    "6. [Feature Importance Analysis](#feature-importance)\n",
    "7. [Results Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from data_generator import HousePriceDataGenerator\n",
    "from data_preprocessor import HousePricePreprocessor\n",
    "from model_trainer import HousePriceModelTrainer\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset if it doesn't exist\n",
    "data_path = '../data/house_data_more_logic.xlsx'\n",
    "\n",
    "if not Path(data_path).exists():\n",
    "    print(\"üìä Generating synthetic dataset...\")\n",
    "    generator = HousePriceDataGenerator(random_seed=42)\n",
    "    dataset = generator.generate_dataset(num_samples=300, save_path=data_path)\n",
    "    print(\"‚úÖ Dataset generated successfully!\")\n",
    "else:\n",
    "    print(\"üìÅ Dataset already exists, loading...\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = HousePricePreprocessor()\n",
    "data = preprocessor.load_data(data_path)\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing {#preprocessing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "quality_report = preprocessor.check_data_quality(data)\n",
    "print(\"Data Quality Report:\")\n",
    "print(f\"Shape: {quality_report['shape']}\")\n",
    "print(f\"Missing values: {sum(quality_report['missing_values'].values())}\")\n",
    "print(f\"Duplicates: {quality_report['duplicates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and prepare features\n",
    "data_clean = preprocessor.handle_missing_values(data)\n",
    "X, y = preprocessor.prepare_features(data_clean, include_engineered=True)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{i+1:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features and split data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = preprocessor.split_data(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Processed features: {X_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training {#training}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "trainer = HousePriceModelTrainer()\n",
    "\n",
    "print(\"Available models:\")\n",
    "for i, model_name in enumerate(trainer.available_models.keys(), 1):\n",
    "    print(f\"{i}. {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models (without hyperparameter tuning for speed)\n",
    "print(\"ü§ñ Training all models...\")\n",
    "models = trainer.train_all_models(X_train, y_train, tune_hyperparameters=False)\n",
    "print(f\"\\n‚úÖ Successfully trained {len(models)} models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation {#evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "print(\"üìà Evaluating all models...\")\n",
    "results_df = trainer.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "print(\"\\nüèÜ Model Performance Results:\")\n",
    "print(\"=\" * 80)\n",
    "results_display = results_df.copy()\n",
    "results_display['rmse'] = results_display['rmse'].apply(lambda x: f\"${x:,.0f}\")\n",
    "results_display['mae'] = results_display['mae'].apply(lambda x: f\"${x:,.0f}\")\n",
    "results_display['r2'] = results_display['r2'].apply(lambda x: f\"{x:.4f}\")\n",
    "results_display['mape'] = results_display['mape'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "print(results_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "print(\"üîÑ Performing cross-validation...\")\n",
    "cv_results = trainer.cross_validate_models(X_train, y_train, cv_folds=5)\n",
    "\n",
    "print(\"\\nüìä Cross-Validation Results:\")\n",
    "print(\"=\" * 50)\n",
    "cv_display = cv_results.copy()\n",
    "cv_display['CV_RMSE_Mean'] = cv_display['CV_RMSE_Mean'].apply(lambda x: f\"${x:,.0f}\")\n",
    "cv_display['CV_RMSE_Std'] = cv_display['CV_RMSE_Std'].apply(lambda x: f\"${x:,.0f}\")\n",
    "print(cv_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison {#comparison}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model comparison\n",
    "trainer.plot_model_comparison(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for best model\n",
    "print(f\"üìä Plotting predictions for best model: {trainer.best_model_name}\")\n",
    "trainer.plot_predictions(X_test, y_test, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis {#feature-importance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "try:\n",
    "    feature_names = preprocessor.get_feature_names()\n",
    "    print(f\"Total features after preprocessing: {len(feature_names)}\")\n",
    "    \n",
    "    # Plot feature importance for tree-based models\n",
    "    tree_models = ['random_forest', 'gradient_boosting']\n",
    "    \n",
    "    for model_name in tree_models:\n",
    "        if model_name in trainer.models:\n",
    "            print(f\"\\nüå≥ Feature importance for {model_name}:\")\n",
    "            importance_df = trainer.get_feature_importance(feature_names, model_name, top_n=15)\n",
    "            if importance_df is not None:\n",
    "                trainer.plot_feature_importance(feature_names, model_name, top_n=15, figsize=(10, 8))\n",
    "                \n",
    "                # Display top 10 features\n",
    "                print(\"\\nTop 10 Most Important Features:\")\n",
    "                for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
    "                    print(f\"{i:2d}. {row['feature']:30s}: {row['importance']:.4f}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Could not analyze feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary {#summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéØ FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìä Dataset Information:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(data)}\")\n",
    "print(f\"   ‚Ä¢ Original features: {len(X.columns)}\")\n",
    "print(f\"   ‚Ä¢ Processed features: {X_processed.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   ‚Ä¢ Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "print(f\"\\nü§ñ Model Training:\")\n",
    "print(f\"   ‚Ä¢ Models trained: {len(trainer.models)}\")\n",
    "print(f\"   ‚Ä¢ Best model: {trainer.best_model_name}\")\n",
    "\n",
    "best_metrics = trainer.results[trainer.best_model_name]\n",
    "print(f\"\\nüèÜ Best Model Performance ({trainer.best_model_name}):\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${best_metrics['rmse']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {best_metrics['r2']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE: ${best_metrics['mae']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ MAPE: {best_metrics['mape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìà Model Interpretation:\")\n",
    "print(f\"   ‚Ä¢ The model explains {best_metrics['r2']*100:.1f}% of price variance\")\n",
    "print(f\"   ‚Ä¢ Average prediction error: ${best_metrics['rmse']:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Typical error percentage: {best_metrics['mape']:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis completed successfully!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for future reference\n",
    "results_df.to_csv('../results/model_results.csv')\n",
    "cv_results.to_csv('../results/cv_results.csv')\n",
    "print(\"üíæ Results saved to ../results/ directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
